{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tianananana/MAML-Naive-Walkthrough/blob/main/v0_MAML_P%26P_(Manual).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation of MAML with the Single Neuron Neural Network Model. v0 uses manual calculation of the gradient.\n"
      ],
      "metadata": {
        "id": "ozsKKgROdb8_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmBlcu9WdU4u"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model"
      ],
      "metadata": {
        "id": "lFc6M1Xed94T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleNet():\n",
        "  def __init__(self):\n",
        "    psi = torch.tensor([1.], requires_grad=True) # task specific initializati\n",
        "    self.weight = psi # set initial weight to 1\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    return self.weight * x"
      ],
      "metadata": {
        "id": "STvNka7Pd9kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create datasets"
      ],
      "metadata": {
        "id": "qp-JeEm0d1wm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We define 2 datasets for our case. \n",
        "D1 = {'query': torch.tensor([(1, 2)], dtype=torch.int64), 'support': torch.tensor([(2, 4), (3, 1)])} # (x, y) pairs for query (Q1) and support (S1) set.\n",
        "D2 = {'query': torch.tensor([(4, 1)], dtype=torch.int64), 'support': torch.tensor([(5, 3), (6, 0)])}\n",
        "D_all = [D1, D2]"
      ],
      "metadata": {
        "id": "RZnCPixKdznP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function"
      ],
      "metadata": {
        "id": "6-EoIYsvOKLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" LOSS FUNCTIONS \"\"\"\n",
        "def loss(weight, dataset, mode='train'):\n",
        "  '''\n",
        "  Regression loss over dataset\n",
        "  '''\n",
        "  # Eqn 5\n",
        "  if mode == 'train':\n",
        "    data = dataset['support']\n",
        "  if mode == 'test':\n",
        "    data = dataset['query']\n",
        "  print(weight)\n",
        "  return torch.sum((data[:, 1] - weight * data[:, 0])**2)"
      ],
      "metadata": {
        "id": "AGCOvWDQf05w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" TASK SPECIFIC FUNCTIONS \"\"\"\n",
        "def inner_gradient(net, dataset, mode='train', weight=0):\n",
        "  # Eqn 6\n",
        "  if mode == 'train':\n",
        "    data = dataset['support']\n",
        "    weight = net.weight\n",
        "  if mode == 'test':\n",
        "    data = dataset['query']\n",
        "    weight = weight # manually pass in task-specific weights\n",
        "\n",
        "  # Manual formula for task-specific gradient\n",
        "  task_specific_gradients = -2 * torch.sum(data[:, 0] * (data[:, 1] - weight.item() * data[:, 0]))\n",
        "  return task_specific_gradients\n",
        "\n",
        "def inner_weight(net, dataset, alpha=0.1):\n",
        "  ''' Compute task-specific (inner) weights on the support set\n",
        "  param net: meta weight\n",
        "  param dataset:\n",
        "  param alpha:\n",
        "  '''\n",
        "  # Eqn 7\n",
        "  task_specific_weight = net.weight - alpha * inner_gradient(net, dataset, mode='train')\n",
        "  return task_specific_weight"
      ],
      "metadata": {
        "id": "QQA0a3TCisAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" META FUNCTIONS \"\"\"\n",
        "\n",
        "def meta_gradient(net, dataset, weight, mode='test', alpha=0.1):\n",
        "  # Eqn 12\n",
        "  support = dataset['support']\n",
        "\n",
        "  # Manual gradient formula of L wrt phi_j\n",
        "  ddag = inner_gradient(net, dataset, mode='test', weight=weight)\n",
        "  # Manual gradient formula of phi_j wrt theta_0\n",
        "  dag = torch.tensor([1]) - 2 * alpha * torch.sum(support[:, 0]**2)\n",
        "  # Compute using chain rule\n",
        "  new_meta_gradient = ddag * dag\n",
        "  return new_meta_gradient\n",
        "\n",
        "\n",
        "def meta_weight(net, datasets, weight, beta=0.5):\n",
        "  '''\n",
        "  Compute meta (outer) weights on the query set\n",
        "  param weight: weight vector of task specific weights\n",
        "  '''\n",
        "  # Eqn 11\n",
        "  all_meta_gradient = torch.tensor(list((map(lambda i: meta_gradient(net, datasets[i], weight=weight[i], mode='test'), list(range(len(datasets)))))))\n",
        "  net.weight = net.weight - (beta * torch.sum(all_meta_gradient))\n",
        "  return net.weight"
      ],
      "metadata": {
        "id": "m-Sqg_NIgXry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## UNIT TEST ##\n",
        "net = SingleNet()\n",
        "# Output task-specific gradient\n",
        "inner_grad1 = inner_gradient(net, D1, mode='train')\n",
        "inner_grad2 = inner_gradient(net, D2, mode='train')\n",
        "print(f\"{inner_grad1=}\")\n",
        "print(f\"{inner_grad2=}\")\n",
        "print(\"\")\n",
        "\n",
        "# Output task-specific weights\n",
        "w1 = inner_weight(net, D1)\n",
        "w2 = inner_weight(net, D2)\n",
        "print(f\"{w1=}\")\n",
        "print(f\"{w2=}\")\n",
        "print(\"\")\n",
        "\n",
        "# Output meta gradient\n",
        "meta_grad1 = meta_gradient(net, D1, w1, mode='test', alpha=0.1)\n",
        "meta_grad2 = meta_gradient(net, D2, w2, mode='test', alpha=0.1)\n",
        "print(f\"{meta_grad1=}\")\n",
        "print(f\"{meta_grad2=}\")\n",
        "print(\"\")\n",
        "\n",
        "# Output new meta weight\n",
        "theta_1 = meta_weight(net, D_all, [w1, w2])\n",
        "print(f\"{theta_1=}\")\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoXp_HKmKGCT",
        "outputId": "6161d2d3-61b1-4094-af47-04abedbf6e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inner_grad1=tensor(4.)\n",
            "inner_grad2=tensor(92.)\n",
            "\n",
            "w1=tensor([0.6000], grad_fn=<SubBackward0>)\n",
            "w2=tensor([-8.2000], grad_fn=<SubBackward0>)\n",
            "\n",
            "meta_grad1=tensor([4.4800])\n",
            "meta_grad2=tensor([3028.4800])\n",
            "\n",
            "theta_1=tensor([-1515.4800], grad_fn=<SubBackward0>)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}